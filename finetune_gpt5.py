"""
GPT-5ã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿè¡Œ
"""

import json
import time
from pathlib import Path
from datetime import datetime, timedelta
from tqdm import tqdm
from api_key_manager import APIKeyManager
from openai import OpenAI

class GPT5FineTuner:
    def __init__(self):
        manager = APIKeyManager()
        api_key = manager.get_key("OPENAI_API_KEY")
        
        if not api_key:
            raise ValueError("OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        self.client = OpenAI(api_key=api_key)
        self.training_file_id = None
        self.validation_file_id = None
        self.job_id = None
    
    def upload_dataset_with_progress(self, train_file: Path, val_file: Path = None):
        """ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ä»˜ãã§ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"""
        
        print("ğŸ“¤ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­...")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’å–å¾—
        train_size = train_file.stat().st_size
        
        # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ä»˜ãï¼‰
        with tqdm(total=train_size, unit='B', unit_scale=True, desc="ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿") as pbar:
            with open(train_file, "rb") as f:
                response = self.client.files.create(
                    file=f,
                    purpose="fine-tune"
                )
                self.training_file_id = response.id
                pbar.update(train_size)
        
        print(f"âœ… ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ•ã‚¡ã‚¤ãƒ«: {self.training_file_id}")
        
        # æ¤œè¨¼ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        if val_file and val_file.exists():
            val_size = val_file.stat().st_size
            
            with tqdm(total=val_size, unit='B', unit_scale=True, desc="æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿") as pbar:
                with open(val_file, "rb") as f:
                    response = self.client.files.create(
                        file=f,
                        purpose="fine-tune"
                    )
                    self.validation_file_id = response.id
                    pbar.update(val_size)
            
            print(f"âœ… æ¤œè¨¼ãƒ•ã‚¡ã‚¤ãƒ«: {self.validation_file_id}")
        
        return self.training_file_id, self.validation_file_id
    
    def try_gpt5_models(self, suffix="travel-jp-gpt5"):
        """GPT-5ç³»ãƒ¢ãƒ‡ãƒ«ã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’è©¦è¡Œ"""
        
        # GPT-5ç³»ãƒ¢ãƒ‡ãƒ«ã®ãƒªã‚¹ãƒˆï¼ˆå„ªå…ˆé †ï¼‰
        gpt5_models = [
            "gpt-5",
            "gpt-5-2025-08-07",
            "gpt-5-nano",
            "gpt-5-nano-2025-08-07",
            "gpt-5-mini",
            "gpt-5-mini-2025-08-07"
        ]
        
        for model in gpt5_models:
            print(f"\nğŸ¯ {model} ã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’è©¦è¡Œ...")
            
            try:
                # ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¸ãƒ§ãƒ–ã‚’ä½œæˆ
                job_params = {
                    "training_file": self.training_file_id,
                    "model": model,
                    "suffix": suffix
                }
                
                # æ¤œè¨¼ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚‹å ´åˆã¯è¿½åŠ 
                if self.validation_file_id:
                    job_params["validation_file"] = self.validation_file_id
                
                # GPT-5ç”¨ã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆæ¨æ¸¬ï¼‰
                job_params["hyperparameters"] = {
                    "n_epochs": 2,  # GPT-5ã¯åŠ¹ç‡ãŒè‰¯ã„ã‹ã‚‚ã—ã‚Œãªã„ã®ã§å°‘ãªã‚
                    "learning_rate_multiplier": 0.05  # ã‚ˆã‚Šä½ã„å­¦ç¿’ç‡
                }
                
                response = self.client.fine_tuning.jobs.create(**job_params)
                self.job_id = response.id
                
                print(f"âœ… ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¸ãƒ§ãƒ–é–‹å§‹: {self.job_id}")
                print(f"   ãƒ¢ãƒ‡ãƒ«: {model}")
                print(f"   ã‚µãƒ•ã‚£ãƒƒã‚¯ã‚¹: {suffix}")
                
                return self.job_id, model
                
            except Exception as e:
                error_str = str(e)
                print(f"âŒ {model} ã§ã‚¨ãƒ©ãƒ¼: {error_str}")
                
                if "not available" in error_str.lower() or "does not exist" in error_str.lower():
                    print(f"   â†’ {model} ã¯ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«å¯¾å¿œã—ã¦ã„ã¾ã›ã‚“")
                    continue
                else:
                    print(f"   â†’ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
                    continue
        
        # å…¨ã¦ã®GPT-5ãƒ¢ãƒ‡ãƒ«ãŒå¤±æ•—ã—ãŸå ´åˆ
        print("\nâš ï¸  ã™ã¹ã¦ã®GPT-5ãƒ¢ãƒ‡ãƒ«ã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãŒå¤±æ•—ã—ã¾ã—ãŸ")
        print("\nğŸ’¡ ä»£æ›¿æ¡ˆã¨ã—ã¦ gpt-4o ã¾ãŸã¯ gpt-4o-mini ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„")
        return None, None
    
    def monitor_with_eta(self, model_name):
        """é€²æ—ã¨ETAè¡¨ç¤ºä»˜ãã§ç›£è¦–"""
        
        if not self.job_id:
            print("âŒ ã‚¸ãƒ§ãƒ–IDãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return
        
        print(f"\nğŸ“Š ã‚¸ãƒ§ãƒ–ç›£è¦–ä¸­: {self.job_id} ({model_name})")
        
        start_time = time.time()
        last_status = None
        status_stages = {
            "validating_files": 5,
            "queued": 15,
            "running": 85,
            "succeeded": 100
        }
        
        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã‚’ä½œæˆ
        with tqdm(total=100, desc=f"GPT-5 ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°", unit="%", 
                  bar_format='{desc}: {percentage:3.0f}%|{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]') as pbar:
            
            try:
                while True:
                    job = self.client.fine_tuning.jobs.retrieve(self.job_id)
                    
                    # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãŒå¤‰ã‚ã£ãŸã‚‰æ›´æ–°
                    if job.status != last_status:
                        last_status = job.status
                        
                        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã‚’æ›´æ–°
                        if job.status in status_stages:
                            target_progress = status_stages[job.status]
                            current_progress = pbar.n
                            if target_progress > current_progress:
                                pbar.update(target_progress - current_progress)
                        
                        # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤º
                        elapsed = time.time() - start_time
                        elapsed_str = str(timedelta(seconds=int(elapsed)))
                        
                        if job.status == "validating_files":
                            tqdm.write(f"ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼ä¸­... (çµŒé: {elapsed_str})")
                        elif job.status == "queued":
                            tqdm.write(f"â³ ã‚­ãƒ¥ãƒ¼ã§å¾…æ©Ÿä¸­... (çµŒé: {elapsed_str})")
                        elif job.status == "running":
                            tqdm.write(f"ğŸš€ GPT-5 ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿè¡Œä¸­... (çµŒé: {elapsed_str})")
                            # GPT-5ã¯é«˜æ€§èƒ½ãªã®ã§æ¨å®šæ™‚é–“ã¯çŸ­ã‚
                            estimated_total = 600  # 10åˆ†ï¼ˆæ¨æ¸¬ï¼‰
                            remaining = max(0, estimated_total - elapsed)
                            remaining_str = str(timedelta(seconds=int(remaining)))
                            tqdm.write(f"   æ¨å®šæ®‹ã‚Šæ™‚é–“: {remaining_str}")
                    
                    # å®Œäº†ãƒã‚§ãƒƒã‚¯
                    if job.status == "succeeded":
                        pbar.update(100 - pbar.n)  # 100%ã«ã™ã‚‹
                        elapsed = time.time() - start_time
                        elapsed_str = str(timedelta(seconds=int(elapsed)))
                        
                        tqdm.write(f"\nğŸ‰ GPT-5 ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å®Œäº†ï¼")
                        tqdm.write(f"   ç·æ™‚é–“: {elapsed_str}")
                        tqdm.write(f"   ãƒ¢ãƒ‡ãƒ«ID: {job.fine_tuned_model}")
                        return job.fine_tuned_model
                    
                    elif job.status == "failed":
                        tqdm.write(f"\nâŒ ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å¤±æ•—")
                        if hasattr(job, 'error') and job.error:
                            tqdm.write(f"   ã‚¨ãƒ©ãƒ¼: {job.error}")
                        return None
                    
                    elif job.status == "cancelled":
                        tqdm.write(f"\nâš ï¸  ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãŒã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸ")
                        return None
                    
                    time.sleep(5)  # 5ç§’ã”ã¨ã«ãƒã‚§ãƒƒã‚¯
                    
            except KeyboardInterrupt:
                tqdm.write("\n\nâš ï¸  ç›£è¦–ã‚’ä¸­æ­¢ã—ã¾ã—ãŸ")
                tqdm.write(f"   ã‚¸ãƒ§ãƒ–ã¯ç¶™ç¶šä¸­ã§ã™: {self.job_id}")
                return None
    
    def test_gpt5_model(self, model_id):
        """GPT-5ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ†ã‚¹ãƒˆ"""
        
        print(f"\nğŸ§ª GPT-5ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ†ã‚¹ãƒˆ: {model_id}")
        
        test_prompts = [
            "æ±äº¬ã‹ã‚‰å¤§é˜ªã¸ã®ç§»å‹•æ–¹æ³•ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚",
            "åŒ—æµ·é“æ—…è¡Œã®ãŠã™ã™ã‚æ™‚æœŸã¯ï¼Ÿ", 
            "å¯Œå£«å±±ã«ç™»ã‚‹ã®ã«å¿…è¦ãªè£…å‚™ã¯ï¼Ÿ",
            "JRãƒ‘ã‚¹ã®ä½¿ã„æ–¹ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚"
        ]
        
        for i, prompt in enumerate(test_prompts, 1):
            print(f"\nã€GPT-5ãƒ†ã‚¹ãƒˆ {i}/{len(test_prompts)}ã€‘")
            print(f"ğŸ‘¤ è³ªå•: {prompt}")
            
            try:
                response = self.client.chat.completions.create(
                    model=model_id,
                    messages=[
                        {"role": "system", "content": "ã‚ãªãŸã¯è¦ªåˆ‡ã§çŸ¥è­˜è±Šå¯Œãªæ—…è¡Œä»£ç†åº—ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ã€‚"},
                        {"role": "user", "content": prompt}
                    ],
                    max_completion_tokens=200
                )
                
                print(f"ğŸ¤– GPT-5å›ç­”: {response.choices[0].message.content}")
                
            except Exception as e:
                print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    
    print("=" * 60)
    print("ğŸš€ GPT-5 ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°")
    print("=" * 60)
    
    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æº–å‚™
    from prepare_travel_dataset import create_travel_dataset
    train_file, val_file = create_travel_dataset()
    
    # ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒŠãƒ¼ã®åˆæœŸåŒ–
    tuner = GPT5FineTuner()
    
    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    tuner.upload_dataset_with_progress(train_file, val_file)
    
    # GPT-5ã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°é–‹å§‹
    job_id, model_name = tuner.try_gpt5_models()
    
    if job_id and model_name:
        # ã‚¸ãƒ§ãƒ–ã®ç›£è¦–
        model_id = tuner.monitor_with_eta(model_name)
        
        if model_id:
            # GPT-5ãƒ¢ãƒ‡ãƒ«ã®ãƒ†ã‚¹ãƒˆ
            tuner.test_gpt5_model(model_id)
            
            print("\n" + "=" * 60)
            print("ğŸ‰ GPT-5 ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å®Œäº†ï¼")
            print(f"   ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«: {model_name}")
            print(f"   ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ID: {model_id}")
            print("\nä½¿ç”¨æ–¹æ³•:")
            print(f'   model="{model_id}"')
            print("=" * 60)
        else:
            print("\nâš ï¸  ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãŒå®Œäº†ã—ã¦ã„ã¾ã›ã‚“")
            print(f"   ã‚¸ãƒ§ãƒ–ID: {job_id}")
    else:
        print("\nâŒ GPT-5ã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’é–‹å§‹ã§ãã¾ã›ã‚“ã§ã—ãŸ")
        print("\nğŸ’¡ gpt-4o-mini ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚’ãŠã™ã™ã‚ã—ã¾ã™:")
        print("   python finetune_with_gpu.py")


if __name__ == "__main__":
    main()