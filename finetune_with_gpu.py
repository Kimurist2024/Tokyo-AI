"""
GPUå¯¾å¿œï¼†é€²æ—è¡¨ç¤ºä»˜ããƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import json
import time
from pathlib import Path
from datetime import datetime, timedelta
from tqdm import tqdm
from api_key_manager import APIKeyManager
from openai import OpenAI

class GPUFineTuner:
    def __init__(self):
        manager = APIKeyManager()
        api_key = manager.get_key("OPENAI_API_KEY")
        
        if not api_key:
            raise ValueError("OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        self.client = OpenAI(api_key=api_key)
        self.training_file_id = None
        self.validation_file_id = None
        self.job_id = None
    
    def upload_dataset_with_progress(self, train_file: Path, val_file: Path = None):
        """ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ä»˜ãã§ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"""
        
        print("ğŸ“¤ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­...")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’å–å¾—
        train_size = train_file.stat().st_size
        
        # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ä»˜ãï¼‰
        with tqdm(total=train_size, unit='B', unit_scale=True, desc="ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿") as pbar:
            with open(train_file, "rb") as f:
                # ãƒ•ã‚¡ã‚¤ãƒ«å…¨ä½“ã‚’èª­ã¿è¾¼ã¿
                file_content = f.read()
                pbar.update(train_size)
                
                # OpenAIã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
                response = self.client.files.create(
                    file=file_content,
                    purpose="fine-tune"
                )
                self.training_file_id = response.id
        
        print(f"âœ… ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ•ã‚¡ã‚¤ãƒ«: {self.training_file_id}")
        
        # æ¤œè¨¼ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        if val_file and val_file.exists():
            val_size = val_file.stat().st_size
            
            with tqdm(total=val_size, unit='B', unit_scale=True, desc="æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿") as pbar:
                with open(val_file, "rb") as f:
                    file_content = f.read()
                    pbar.update(val_size)
                    
                    response = self.client.files.create(
                        file=file_content,
                        purpose="fine-tune"
                    )
                    self.validation_file_id = response.id
            
            print(f"âœ… æ¤œè¨¼ãƒ•ã‚¡ã‚¤ãƒ«: {self.validation_file_id}")
        
        return self.training_file_id, self.validation_file_id
    
    def start_gpu_finetuning(self, model="gpt-4o-mini-2024-07-18", suffix="travel-jp-gpu"):
        """GPUæœ€é©åŒ–ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¸ãƒ§ãƒ–ã‚’é–‹å§‹"""
        
        print(f"\nğŸš€ GPUæœ€é©åŒ–ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’é–‹å§‹...")
        print(f"   ãƒ¢ãƒ‡ãƒ«: {model}")
        
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¸ãƒ§ãƒ–ã‚’ä½œæˆï¼ˆGPUæœ€é©åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰
            job_params = {
                "training_file": self.training_file_id,
                "model": model,
                "suffix": suffix,
                "hyperparameters": {
                    "n_epochs": 3,  # ã‚¨ãƒãƒƒã‚¯æ•°
                    "batch_size": 4,  # GPUç”¨ã«æœ€é©åŒ–ã•ã‚ŒãŸãƒãƒƒãƒã‚µã‚¤ã‚º
                    "learning_rate_multiplier": 0.1  # å­¦ç¿’ç‡ã®èª¿æ•´
                }
            }
            
            # æ¤œè¨¼ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚‹å ´åˆã¯è¿½åŠ 
            if self.validation_file_id:
                job_params["validation_file"] = self.validation_file_id
            
            response = self.client.fine_tuning.jobs.create(**job_params)
            self.job_id = response.id
            
            print(f"âœ… ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¸ãƒ§ãƒ–é–‹å§‹: {self.job_id}")
            print(f"   ã‚µãƒ•ã‚£ãƒƒã‚¯ã‚¹: {suffix}")
            print(f"   GPUæœ€é©åŒ–: ãƒãƒƒãƒã‚µã‚¤ã‚º=4, ã‚¨ãƒãƒƒã‚¯=3")
            
            return self.job_id
            
        except Exception as e:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def monitor_with_eta(self):
        """é€²æ—ã¨ETAï¼ˆæ¨å®šå®Œäº†æ™‚é–“ï¼‰ã‚’è¡¨ç¤ºã—ãªãŒã‚‰ç›£è¦–"""
        
        if not self.job_id:
            print("âŒ ã‚¸ãƒ§ãƒ–IDãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return
        
        print(f"\nğŸ“Š ã‚¸ãƒ§ãƒ–ç›£è¦–ä¸­: {self.job_id}")
        
        start_time = time.time()
        last_status = None
        status_stages = {
            "validating_files": 5,
            "queued": 10,
            "running": 85,
            "succeeded": 100
        }
        
        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã‚’ä½œæˆ
        with tqdm(total=100, desc="ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°é€²æ—", unit="%", 
                  bar_format='{desc}: {percentage:3.0f}%|{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]') as pbar:
            
            try:
                while True:
                    job = self.client.fine_tuning.jobs.retrieve(self.job_id)
                    
                    # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãŒå¤‰ã‚ã£ãŸã‚‰æ›´æ–°
                    if job.status != last_status:
                        last_status = job.status
                        
                        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã‚’æ›´æ–°
                        if job.status in status_stages:
                            target_progress = status_stages[job.status]
                            current_progress = pbar.n
                            if target_progress > current_progress:
                                pbar.update(target_progress - current_progress)
                        
                        # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤º
                        elapsed = time.time() - start_time
                        elapsed_str = str(timedelta(seconds=int(elapsed)))
                        
                        if job.status == "validating_files":
                            tqdm.write(f"ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼ä¸­... (çµŒé: {elapsed_str})")
                        elif job.status == "queued":
                            tqdm.write(f"â³ ã‚­ãƒ¥ãƒ¼ã§å¾…æ©Ÿä¸­... (çµŒé: {elapsed_str})")
                        elif job.status == "running":
                            tqdm.write(f"ğŸƒ ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿè¡Œä¸­... (çµŒé: {elapsed_str})")
                            tqdm.write("   GPUã§é«˜é€Ÿå‡¦ç†ä¸­...")
                            # æ¨å®šæ®‹ã‚Šæ™‚é–“ï¼ˆçµŒé¨“å€¤ãƒ™ãƒ¼ã‚¹ï¼‰
                            estimated_total = 1200  # 20åˆ†ï¼ˆç§’ï¼‰
                            remaining = max(0, estimated_total - elapsed)
                            remaining_str = str(timedelta(seconds=int(remaining)))
                            tqdm.write(f"   æ¨å®šæ®‹ã‚Šæ™‚é–“: {remaining_str}")
                    
                    # å®Œäº†ãƒã‚§ãƒƒã‚¯
                    if job.status == "succeeded":
                        pbar.update(100 - pbar.n)  # 100%ã«ã™ã‚‹
                        elapsed = time.time() - start_time
                        elapsed_str = str(timedelta(seconds=int(elapsed)))
                        
                        tqdm.write(f"\nâœ… ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å®Œäº†ï¼")
                        tqdm.write(f"   ç·æ™‚é–“: {elapsed_str}")
                        tqdm.write(f"   ãƒ¢ãƒ‡ãƒ«ID: {job.fine_tuned_model}")
                        return job.fine_tuned_model
                    
                    elif job.status == "failed":
                        tqdm.write(f"\nâŒ ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å¤±æ•—")
                        if hasattr(job, 'error') and job.error:
                            tqdm.write(f"   ã‚¨ãƒ©ãƒ¼: {job.error}")
                        return None
                    
                    elif job.status == "cancelled":
                        tqdm.write(f"\nâš ï¸  ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãŒã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸ")
                        return None
                    
                    # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­ã¯è©³ç´°æƒ…å ±ã‚’å–å¾—
                    if job.status == "running":
                        try:
                            # ã‚¤ãƒ™ãƒ³ãƒˆãƒ­ã‚°ã‹ã‚‰é€²æ—ã‚’å–å¾—
                            events = self.client.fine_tuning.jobs.list_events(
                                fine_tuning_job_id=self.job_id,
                                limit=1
                            )
                            if events.data:
                                latest_event = events.data[0]
                                if latest_event.message:
                                    # ã‚¹ãƒ†ãƒƒãƒ—æƒ…å ±ã‚’æŠ½å‡º
                                    if "Step" in latest_event.message:
                                        tqdm.write(f"   {latest_event.message}")
                        except:
                            pass
                    
                    time.sleep(5)  # 5ç§’ã”ã¨ã«ãƒã‚§ãƒƒã‚¯
                    
            except KeyboardInterrupt:
                tqdm.write("\n\nâš ï¸  ç›£è¦–ã‚’ä¸­æ­¢ã—ã¾ã—ãŸ")
                tqdm.write(f"   ã‚¸ãƒ§ãƒ–ã¯ç¶™ç¶šä¸­ã§ã™: {self.job_id}")
                return None
    
    def test_finetuned_model(self, model_id):
        """ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ†ã‚¹ãƒˆ"""
        
        print(f"\nğŸ§ª ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ†ã‚¹ãƒˆ: {model_id}")
        
        test_prompts = [
            "æ±äº¬ã‹ã‚‰å¤§é˜ªã¸ã®ç§»å‹•æ–¹æ³•ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚",
            "åŒ—æµ·é“æ—…è¡Œã®ãŠã™ã™ã‚æ™‚æœŸã¯ï¼Ÿ",
            "JRãƒ‘ã‚¹ã®ä½¿ã„æ–¹ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚"
        ]
        
        for i, prompt in enumerate(test_prompts, 1):
            print(f"\nã€ãƒ†ã‚¹ãƒˆ {i}/3ã€‘")
            print(f"ğŸ‘¤ è³ªå•: {prompt}")
            
            try:
                response = self.client.chat.completions.create(
                    model=model_id,
                    messages=[
                        {"role": "system", "content": "ã‚ãªãŸã¯è¦ªåˆ‡ã§çŸ¥è­˜è±Šå¯Œãªæ—…è¡Œä»£ç†åº—ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ã€‚"},
                        {"role": "user", "content": prompt}
                    ],
                    max_tokens=150
                )
                
                print(f"ğŸ¤– å›ç­”: {response.choices[0].message.content}")
                
            except Exception as e:
                print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")


def check_job_status(job_id: str):
    """æ—¢å­˜ã®ã‚¸ãƒ§ãƒ–ã®çŠ¶æ…‹ã‚’ç¢ºèª"""
    
    manager = APIKeyManager()
    client = OpenAI(api_key=manager.get_key("OPENAI_API_KEY"))
    
    print(f"ğŸ“Š ã‚¸ãƒ§ãƒ–ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç¢ºèª: {job_id}")
    
    try:
        job = client.fine_tuning.jobs.retrieve(job_id)
        
        print(f"\nçŠ¶æ…‹: {job.status}")
        print(f"ä½œæˆæ—¥æ™‚: {job.created_at}")
        
        if job.status == "succeeded":
            print(f"âœ… å®Œäº†!")
            print(f"ãƒ¢ãƒ‡ãƒ«ID: {job.fine_tuned_model}")
        elif job.status == "running":
            print("ğŸƒ å®Ÿè¡Œä¸­...")
            # æœ€æ–°ã®ã‚¤ãƒ™ãƒ³ãƒˆã‚’è¡¨ç¤º
            events = client.fine_tuning.jobs.list_events(
                fine_tuning_job_id=job_id,
                limit=3
            )
            if events.data:
                print("\næœ€æ–°ã®ã‚¤ãƒ™ãƒ³ãƒˆ:")
                for event in events.data:
                    print(f"  - {event.message}")
        
        return job
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        return None


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    
    print("=" * 60)
    print("ğŸ¯ GPUæœ€é©åŒ–ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆé€²æ—è¡¨ç¤ºä»˜ãï¼‰")
    print("=" * 60)
    
    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æº–å‚™
    from prepare_travel_dataset import create_travel_dataset
    train_file, val_file = create_travel_dataset()
    
    # ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒŠãƒ¼ã®åˆæœŸåŒ–
    tuner = GPUFineTuner()
    
    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ä»˜ãï¼‰
    tuner.upload_dataset_with_progress(train_file, val_file)
    
    # GPUæœ€é©åŒ–ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°é–‹å§‹
    job_id = tuner.start_gpu_finetuning()
    
    if job_id:
        # é€²æ—ã¨ETAè¡¨ç¤ºä»˜ãã§ç›£è¦–
        model_id = tuner.monitor_with_eta()
        
        if model_id:
            # ãƒ¢ãƒ‡ãƒ«ã®ãƒ†ã‚¹ãƒˆ
            tuner.test_finetuned_model(model_id)
            
            print("\n" + "=" * 60)
            print("âœ… ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å®Œäº†ï¼")
            print(f"   ãƒ¢ãƒ‡ãƒ«ID: {model_id}")
            print("\nä½¿ç”¨æ–¹æ³•:")
            print(f'   model="{model_id}"')
            print("=" * 60)


if __name__ == "__main__":
    import sys
    if len(sys.argv) > 1:
        # ã‚¸ãƒ§ãƒ–IDãŒæŒ‡å®šã•ã‚ŒãŸã‚‰çŠ¶æ…‹ç¢ºèª
        check_job_status(sys.argv[1])
    else:
        # é€šå¸¸ã®å®Ÿè¡Œ
        main()