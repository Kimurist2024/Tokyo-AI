"""
ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ãƒ†ã‚¹ãƒˆ
"""

from api_key_manager import APIKeyManager
from openai import OpenAI

def test_finetuned_model():
    """ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ†ã‚¹ãƒˆ"""
    
    # ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ID
    model_id = "ft:gpt-4o-mini-2024-07-18:kimurist:travel-jp-gpu:CBaBln2U"
    
    manager = APIKeyManager()
    client = OpenAI(api_key=manager.get_key("OPENAI_API_KEY"))
    
    print("ğŸ§ª ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ†ã‚¹ãƒˆ")
    print(f"   ãƒ¢ãƒ‡ãƒ«ID: {model_id}")
    
    # ãƒ†ã‚¹ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆæ—…è¡Œé–¢é€£ï¼‰
    test_prompts = [
        "æ±äº¬ã‹ã‚‰å¤§é˜ªã¸ã®ç§»å‹•æ–¹æ³•ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚",
        "åŒ—æµ·é“æ—…è¡Œã®ãŠã™ã™ã‚æ™‚æœŸã¯ã„ã¤ã§ã™ã‹ï¼Ÿ",
        "JRãƒ‘ã‚¹ã®ä½¿ã„æ–¹ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚",
        "å¯Œå£«å±±ã«ç™»ã‚‹ã®ã«å¿…è¦ãªè£…å‚™ã¯ï¼Ÿ",
        "äº¬éƒ½ã®ç´…è‘‰ã®è¦‹é ƒã‚’æ•™ãˆã¦ãã ã•ã„ã€‚",
        "æˆç”°ç©ºæ¸¯ã‹ã‚‰éƒ½å¿ƒã¸ã®ç§»å‹•æ–¹æ³•ã¯ï¼Ÿ"
    ]
    
    for i, prompt in enumerate(test_prompts, 1):
        print(f"\nã€ãƒ†ã‚¹ãƒˆ {i}/{len(test_prompts)}ã€‘")
        print(f"ğŸ‘¤ è³ªå•: {prompt}")
        
        try:
            response = client.chat.completions.create(
                model=model_id,
                messages=[
                    {
                        "role": "system", 
                        "content": "ã‚ãªãŸã¯è¦ªåˆ‡ã§çŸ¥è­˜è±Šå¯Œãªæ—…è¡Œä»£ç†åº—ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ã€‚æ—¥æœ¬èªã§ä¸å¯§ã«å¯¾å¿œã—ã¦ãã ã•ã„ã€‚"
                    },
                    {"role": "user", "content": prompt}
                ],
                max_tokens=200,
                temperature=0.7
            )
            
            print(f"ğŸ¤– å›ç­”: {response.choices[0].message.content}")
            print(f"   ä½¿ç”¨ãƒˆãƒ¼ã‚¯ãƒ³: {response.usage.total_tokens}")
            
        except Exception as e:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")

def chat_with_finetuned_model():
    """ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã¨ã®å¯¾è©±"""
    
    model_id = "ft:gpt-4o-mini-2024-07-18:kimurist:travel-jp-gpu:CBaBln2U"
    
    manager = APIKeyManager()
    client = OpenAI(api_key=manager.get_key("OPENAI_API_KEY"))
    
    print("\n" + "=" * 60)
    print("ğŸ’¬ ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã¨ã®å¯¾è©±")
    print("=" * 60)
    print("çµ‚äº†ã™ã‚‹ã«ã¯ 'exit' ã¨å…¥åŠ›ã—ã¦ãã ã•ã„")
    print("-" * 60)
    
    # ä¼šè©±å±¥æ­´
    messages = [
        {
            "role": "system",
            "content": "ã‚ãªãŸã¯è¦ªåˆ‡ã§çŸ¥è­˜è±Šå¯Œãªæ—…è¡Œä»£ç†åº—ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ã€‚æ—¥æœ¬èªã§ä¸å¯§ã«å¯¾å¿œã—ã¦ãã ã•ã„ã€‚"
        }
    ]
    
    while True:
        user_input = input("\nğŸ‘¤ ã‚ãªãŸ: ").strip()
        
        if user_input.lower() in ['exit', 'quit', 'çµ‚äº†']:
            print("\nğŸ‘‹ ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸï¼")
            break
        
        if not user_input:
            continue
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
        messages.append({"role": "user", "content": user_input})
        
        try:
            print("\nğŸ¤– æ—…è¡Œã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ: ", end="", flush=True)
            
            response = client.chat.completions.create(
                model=model_id,
                messages=messages,
                max_tokens=300,
                temperature=0.7,
                stream=True
            )
            
            # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è¡¨ç¤º
            full_response = ""
            for chunk in response:
                if chunk.choices[0].delta.content is not None:
                    content = chunk.choices[0].delta.content
                    print(content, end="", flush=True)
                    full_response += content
            
            print()  # æ”¹è¡Œ
            
            # å¿œç­”ã‚’å±¥æ­´ã«è¿½åŠ 
            messages.append({"role": "assistant", "content": full_response})
            
        except Exception as e:
            print(f"\nâŒ ã‚¨ãƒ©ãƒ¼: {e}")

if __name__ == "__main__":
    print("=" * 60)
    print("ğŸ¯ ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ« ãƒ†ã‚¹ãƒˆ & å¯¾è©±")
    print("=" * 60)
    
    # ã¾ãšãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ
    test_finetuned_model()
    
    # å¯¾è©±ãƒ¢ãƒ¼ãƒ‰é–‹å§‹
    chat_with_finetuned_model()